\chapter{Updates to the Noise Simulation}
\section{A Summary of Previous Fits}

Detector noise is a nuisance in most physics and astronomy experiments. 
In general, detecor noise for PMTs is assumed to be due to random emission from the photocathode.
In this simple model, the noise may be related to the gain and voltage of the PMT, but is independent of external factors.
The noise hits appear uniformly in time with a known or measureable average rate following a Poisson process.

This model of the noise was successfully used in the past in IceCube. 
With the introduction of the lower trigger threshold in DeepCore, however, it quickly became clear that additional sources of noise exist.
These additional hits appeared to occur in 'bursts' on a single PMT extending for up to a millisecond.
Due to the time-correlations of these hits, the phenomenon was labeled \textbf{correlated noise}.

Work done in 2011-2014 \ref{larson_masters} showed that the overall noise of the IceCube and DeepCore detectors is well-modeled using a combination of correlated and uncorrelated noise.
The empirical model, consisting of a Poisson process for electronic noise and a Poisson process-triggered correlated component modeled with a log-normal distribution, contains five free parameters per DOM fit to each DOM using untriggered raw data from the detector collected over a span of approximately 10 minutes.

The 2014 calibrations were fit DOM-by-DOM by minimizing the chi-squared between the untriggered data and simulation produced with parameters identified using a Metropolis-Hastings algorithm.
A distribution of the time between observed hits was used for this fit.
Due to the computationally-intensive nature of the fits, the stopping condition was intentionally loosely defined, with a goodness-of-fit of approximately 10\% used for most DOMs.

The resulting distributions of the number of hit DOMs and the number of accidental triggers due to detector noise were shown to improve significantly after inclusion of the updated noise model.
Analyses at final level reported a significant improvement in fits and a reduction in previously-observed unphysical behavior in fits.
The change in the noise model resulted in a change in the rate of neutrinos at final level of up to 50\% for a standard oscillation selection in DeepCore and general improvements in agreement between data and simulation rates of other low energy analyses.

\section{Limitations and Disagreement with Previous Fits}

While the rate and shape of the accidental triggers improved significantly compared to past attempts, significant disagreement remained.
In particular, the number of triggered events with very few hits (here defined as five or fewer hit DOMs) was shown to still be approximately a factor of two higher in data than in simulation.
This region of the parameter space was shown to be dominated by accidental noise triggers in simulation.

The rates of accidental triggers, as an emergent property of the collection of individual PMTs, contains unknown uncertainties due to the individual uncertainties associated with the noise modeling of each PMT separately.
A rescaling of the simulated accidental rates, while difficult to justify a priori without changing the noise rate themselves, proved to be effective in some distributions.
In particular, the number of hit DOMs was well-modeled with this approach, resulting in an overall rate agreement of better than 95\%. 

An evaluation of the limitations of the previous calibration was begun in 2014, uncovering a number of possible improvements.

The original fits were limited due to a number of factors. 
For example, the fits excluded the effect of atmospheric muons in the detector under the assumption that the approximate hit rate per DOM due to atmospheric muons (approximately 5 Hz) is significantly smaller than the noise hit rate observed in previous calibration (about 600 Hz).

Furthermore, the choice of minimization methods was known to result in potentially-incomplete minimization due to computational limitations.
Due to the nature of the fit distributions, there existed significant degeneracy in the parameter space, leading to further difficulties.

In addition, disagreements over the modeling of PMT effects such as afterpulsing led to fits artificially limited to timescales longer than 10 microseconds, allowing the minimizer to only observe part of the correlated noise distribution.

Full waveforms are only recorded from the detector in the case of HLC hits. 
Because these are rare for noise hits, negligible information was available for fitting at timescales shorter than the FADC readout time of 6.4 microseconds.
The noise model itself was used down to 2 microseconds, however, resulting in uncertainty due to the extrapolation of the noise model to shorter times.
The limit of 2 microseconds was implemented due to the inherent difficulty in characterizing effects at these timescales due to artificial deadtime related to the HLC launch readout. 

\section{Low-dt Noise from Vuvuzela}
In an attempt to address the abitrary limit imposed, a new version of the Vuvuzela code was created with the ability to remove the cutoff.
The resulting noise, labeled \textbf{low-dt} noise for the short timescales ($\Delta$t), was used to produce a simulation of accidental noise triggers for testing without further calibration.
These events were used with standard CORSIKA simulation to test the effect of the low-dt noise on low level variable distributions.

The low-dt noise was shown to increase the rate of accidental triggers, leading to better agreement in data and simulation rates.
The distribution of the number of locally-coincident DOMs improved, primarily due to the increased rate of accidental triggers.

The distribution of the total charge of events was tested for both HLC hits alone and for all hits. 
The charge distribution for HLC hits slightly improved.
However, the charge expected from simulation and data showed significant disagreements using the low-dt noise when looking at the HLC+SLC hit distribution.

This disagreement implied that the number of SLC hits was increased significantly with the additional low-dt noise. 
This demonstrated that the noise distribution at very short timescales was an important effect that deserved further attention.

When the noise distribution is extended to shorter timescales, a fraction of the tail of the distribution falls into a single ATWD window of 322 nanoseconds.
Furthermore, some fraction of the hits in a burst of correlated noise occur within the three bins read out of the FADC for an SLC hit.
With multiple noise hits occuring in such a short time, the DOM will observe a higher voltage in each of the SLC bins.
The result is that SLC hits due to noise no longer occur as single-photoelectron pulses, as is the case when noise hits are rare at the 10 nanosecond timescales, but as an integration of multiple single pulses.

The observation of higher charge in SLC pulses in simulation than data  gives one an indication of the extremely short timescale end of the noise timing distribution.
Alternatively, the charge distribution of each DOM may therefore be used in the fitting procedure in order to characterize the low-dt end of the noise timing distribution.
This provides a direct handle missing from the previous fit, removing some degeneracy that previously existed.

\section{Updating the Fitting Code}
The newly available information provided the potential for improvement in the noise fit distribution as well as a way to remove the abitrary cutoffs used in the previous version of Vuvuzela.

With the opportunity to refit, a number of additional improvements were implemented.
In order to include the effect of atmospheric muons, a collection of long-frame CORSIKA was produced. 
The simulation was halted after photon propagation, giving a collection of muons without detector noise and effects yet applied.

A simulation script was produced to apply the noise, PMT, and DOM simulation for a single DOM using a given set of noise parameters to this long-frame CORSIKA.
Information on the timing and charge of the DOM is put into a ROOT file format to ease plotting and fitting.
The simulation code was wrapped inside of a calling function, simplifying usage inside of the minimization process.

After the simulation for a given set of parameters, histograms are produced for untriggered data and simulation.
As in the previous fits, the time between subsequent hits is used as one of the histograms for calibration of the noise behavior.
In addition, the observed charge on the DOM is also histogrammed for use as a second observable.

The range of the histograms, from 6 microseconds until 1 second in the time between hit and 0-5 photoelectrons per DOM launch, provides sensitivity to the full range of the noise distribution.

Using the two distributions, a Poisson binned likelihood is formed using the standard equations.
In this case, with the simulation in bin $i$ of histogram $j$ denoted by $f_{ji}$ and the data hits in the same bin denoted by $d_{ji}$ and ignoring normalization constants, the log-likelihood takes the form

\begin{equation}
	LLH = \sum_j \sum_i^{\mathtt{nbins}_j} d_{ji} \mathtt{Log}(f_{ji}) + f_{ji}
\end{equation}

For more information on the derivation of the likelihood, see \ref{sec:pLLH}.
The negative log-likelihood, $-LLH$ is minimized as a function of the five noise parameters using the iMinuit, a python wrapper for the minuit2 package.

Initial fits showed a lack of constraining power from high charges in the charge distribution.
To provide more weight to high charges, the histogram of the charges was weighted by the value of the observed charge.
This reduces the weight of very low charge launches, but increases the weight of higher charges.

Additional work showed that the charge distributions between data and simulation demonstrated significant disagreement. 
A scale factor applied to the charge in simulation was introduced as a free parameter in the fit to account for this. 
To limit the computational complexity of the added parameter, the minimization over this charge scale factor is done as a separate step in the calculation.
This assumes that the difference is a calibration issue in the data rather than a simulation problem.
This, in fact, has been shown to be the case, with an updated charge calibration now applied to data at final level.
Further information on the charge disagreement between data and simulation can be found in section \ref{sec:pass2}.

The previous calibration attempts explicitly avoided fitting the behavior below 10 microseconds due to the potential for mismodeled PMT effects.
In particular, it was noted that mismodeled afterpulsing behavior could lead to pulls in the noise parameters.
The default value in simulation, assumed to be 5.6\% for all PMTs, failed to take into account variations in the effects on each individual DOM.
In the updated fit, the afterpulsing behavior has been investigated for each PMT by including an overall scale factor on the afterpulsing probability.

Late pulses, produced by electrons which backscatter to previous dynodes during the multiplication process, were also investigated for their effect on the goodness-of-fit in the noise distributions.
These pulses occur at timescales of 50-200 nanoseconds and therefore are outside of both the SLC charge and timing distribution window.
Regardless, the late pulsing behavior was found to have a small impact due to both the rarity of late pulses as well as the lack of detailed  information to constrain the distribution.

The effect of the afterpulsing parameter allowed some fits to fall into a poor local minimum. 
In those cases, the interplay between the parameters led to a fit that could no longer produce a reasonable fit.
In these cases, the probability of observing an afterpulse following a photoelectron would be moved from 5.6\% to the unrealistically high value of 20\%. 
This would, in turn, force the mean value for the log-normal timing distribution to move toward higher values and the sigma value to become unrealistically large.

These fits were noticeable when looking at the best fit value of the afterpulsing probability, with a distinct population appearing due to this behavior.
In order to constrain the fit to more realistic values, bounds were added to both the log-normal mean and afterpulsing probability. 

Due to the computational power required to produce large amounts of effective livetime, a tiered approach was employed in the calibration process.
Initial fits were seeded with the previous noise parameter fit values obtained in 2014.
For these events, a course binning and short effective livetime of just one minute were used.
In addition, a weak tolerance value was used, allowing the minimizer to quickly migrate to the neighborhood of the global minimum.

When the first tier completes the minimization process, the fit is begun anew with more effective livetime, more bins, and a stronger tolerance.
The second tier used a 5 minute effective livetime.

The third and final tier increased the effective livetime to 10 minutes and again increased the number of bins.

\section{Results of New Noise Fits}
New calibration fits were completed over the course of approximately two months for nearly all DOMs in the IceCube detector.
String 21 was absent from the updated untriggered data and was therefore left unfit.

The noise fits were checked for correlations between parameters after convergence.
One immediately notable feature is the number of DOMs with afterpulsing at the fitter boundary.
The likelihood values associated with these fits, however, appear to be consistent with other fits.
Due to a planned overhaul of the afterpulsing simulation, the fit values of the afterpulsing probabilities have not been adopted for simulation.
Therefore, no further investigation of the probabilities has been persued.

Some of the noise parameters have expected behavior.
In particular, there exists a Poisson process component of the noise model that is assumed to be associated with the electronic noise, which should show increasing rate with increasing depth due to the rising temperature.
This effect, though weak, is apparent after the fitting procedure.

Other parameters should be independent of depth.
As a test of the fits, each of the other parameters is plotted as a function of depth as well.
No significant correlation is observed.

Finally, the likelihood itself should be independent of depth.
This final test shows surprising results in at least two ways:
a 'band' structure appears in the plot. and there appears to be a depth-dependent decrease in the likelihood value, indicating that the lower part of the detector yields better fit results.
This was initially unexpected, given that the noise is an internal property of the DOM and not of the surrounding medium.

This effect occurs due to a combination of factors. 
It is worth noting that the fits are not independent of external factors.
Indeed, the fits themselves use the long-frame CORSIKA to model the effects of muons in the untriggered data from the detector.

This leads to two subtle limitations in the fitting process.
The long-frame CORSIKA is produced with a single flux model, in this case the model of Hoerandel.
Because the long-frame CORSIKA cannot be reweighted to other models, uncertainties or mismodeling in the muon flux can lead to disagreement in the fitting of noise parameters.
The muon flux decreases with increasing depth, resulting in a lower muon contamination, and consequently smaller effects from mismodeling of the muon background, for deeper DOMs. 

In addition, the long-frame CORSIKA implicitly assumes a single model of the ice for photon propagation.
Mismodeling of the scattering and absorption of the ice therefore may also give rise to disagreement in the noise calibration process.
While large-scale properties of the ice are believed to be well-reproduced by the chosen ice model, SpiceLea, there will inevitably be remaining disagreements.

The net effect of these two assumptions in the muon simulation is effectively correlated with the convolution of the ice model and the muon flux.
In particular, the best fits occur where the DOM is either A) well-shielded from light due to muons by the large depth or B) well-shielded due to large absorption in the ice.
In both cases, the contamination from light due to muons in the fitted time and charge distributions will be small, leading to a more 'pure' noise distribution that is well-fit by the assumed model.

The sensitivity of the noise calibration procedure to underlying physics of both the muon flux and the absorption properties in the detector imply that little further improvement is likely without work on one or both issues.
Simulation of long-frame CORSIKA is, unfortunately, unlikely to be updated to a newer flux model in the near-term due to technical limitations.
As the primary uncertainty affecting the goodness-of-fit appears to be due to the visibility and flux of the muons themselves, merely updating to a newer model of the ice will be unlikely to significantly improve the current fit parameters.

The newly calibrated low-dt Vuvuzela was provided to the IceCube simulation group in January of 2015 and quickly integrated into the low-energy simulation chain.
New neutrino, muon, and accidental noise trigger simulations were produced soon thereafter.
The updated noise model shows significantly better agreement in both the total charge distribution and the number of hit DOMs for both HLC and SLC+HLC hits.
The rate of accidental triggers improved relative to previous calibrations, with the remaining rate disagreement reduced from 50\% to approximately 15\%.
Negligible effect was observed in the low-energy neutrino events at final level for existing samples.

